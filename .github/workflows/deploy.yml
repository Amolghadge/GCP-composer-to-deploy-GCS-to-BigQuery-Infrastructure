name: Deploy GCS to BigQuery Infrastructure

on:
  push:
    branches:
      - main
      - develop
  pull_request:
    branches:
      - main
  workflow_dispatch:

env:
  TF_VERSION: 1.5.0
  GCP_REGION: us-central1

jobs:
  terraform-plan:
    name: Terraform Plan
    runs-on: ubuntu-latest
    permissions:
      contents: read
      pull-requests: write

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: ${{ env.TF_VERSION }}

      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v1
        with:
          credentials_json: ${{ secrets.GCP_SA_KEY }}

      - name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@v1

      - name: Initialize Terraform
        working-directory: ./terraform
        run: terraform init

      - name: Validate Terraform
        working-directory: ./terraform
        run: terraform validate

      - name: Format Check
        working-directory: ./terraform
        run: terraform fmt -check -recursive

      - name: Terraform Plan
        working-directory: ./terraform
        env:
          TF_VAR_project_id: ${{ secrets.GCP_PROJECT_ID }}
        run: terraform plan -out=tfplan

      - name: Upload Terraform Plan
        if: github.event_name == 'pull_request'
        uses: actions/upload-artifact@v4
        with:
          name: tfplan
          path: terraform/tfplan

      - name: Comment on PR
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const planOutput = fs.readFileSync('terraform/tfplan-comment.txt', 'utf8');
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: `## Terraform Plan\n\`\`\`\n${planOutput}\n\`\`\``
            });

  validate-dag:
    name: Validate Airflow DAG
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install Airflow
        run: |
          pip install --upgrade pip setuptools wheel
          pip install apache-airflow==2.7.0
          pip install apache-airflow-providers-google>=10.0.0

      - name: Validate DAG Syntax
        run: |
          python -m py_compile dags/gcs_to_bigquery_dag.py

      - name: Check DAG Structure
        run: |
          export AIRFLOW_HOME=$(pwd)
          export AIRFLOW__CORE__DAGS_FOLDER=$(pwd)/dags
          export AIRFLOW__CORE__LOAD_EXAMPLES=False
          export AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=sqlite:////tmp/airflow.db
          export AIRFLOW__CORE__UNIT_TEST_MODE=True
          python dags/gcs_to_bigquery_dag.py

  terraform-apply:
    name: Terraform Apply
    runs-on: ubuntu-latest
    needs: [terraform-plan, validate-dag]
    if: github.ref == 'refs/heads/main' && github.event_name == 'push'
    permissions:
      contents: read

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: ${{ env.TF_VERSION }}

      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v1
        with:
          credentials_json: ${{ secrets.GCP_SA_KEY }}

      - name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@v1

      - name: Initialize Terraform
        working-directory: ./terraform
        run: terraform init

      - name: Terraform Apply
        working-directory: ./terraform
        env:
          TF_VAR_project_id: ${{ secrets.GCP_PROJECT_ID }}
        run: terraform apply -auto-approve

      - name: Get Terraform Outputs
        working-directory: ./terraform
        run: terraform output -json > outputs.json

      - name: Upload Outputs
        uses: actions/upload-artifact@v4
        with:
          name: terraform-outputs
          path: terraform/outputs.json

      - name: Display Outputs
        working-directory: ./terraform
        run: |
          echo "=== Deployment Summary ==="
          terraform output

  deploy-dag:
    name: Deploy DAG to Cloud Composer
    runs-on: ubuntu-latest
    needs: terraform-apply
    if: github.ref == 'refs/heads/main' && github.event_name == 'push'

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v1
        with:
          credentials_json: ${{ secrets.GCP_SA_KEY }}

      - name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@v1

      - name: Deploy DAG to Composer
        run: |
          echo "Deploying DAG to Cloud Composer..."
          
          PROJECT_ID="${{ secrets.GCP_PROJECT_ID }}"
          COMPOSER_ENV="gcs-to-bq-composer"
          REGION="us-central1"
          
          # Get the DAG folder from Composer environment
          DAG_FOLDER=$(gcloud composer environments describe $COMPOSER_ENV \
            --project=$PROJECT_ID \
            --location=$REGION \
            --format='value(config.dagGcsPrefix)')
          
          echo "DAG folder: $DAG_FOLDER"
          
          # Upload DAG to Composer
          gsutil cp dags/gcs_to_bigquery_dag.py $DAG_FOLDER/
          
          echo "DAG deployed successfully!"

      - name: Verify DAG Deployment
        run: |
          PROJECT_ID="${{ secrets.GCP_PROJECT_ID }}"
          COMPOSER_ENV="gcs-to-bq-composer"
          REGION="us-central1"
          
          # Wait for DAG to be picked up (usually 1-2 minutes)
          echo "Waiting for DAG to be registered..."
          sleep 30
          
          # Check if DAG appears in Airflow
          gcloud composer environments run $COMPOSER_ENV \
            --project=$PROJECT_ID \
            --location=$REGION \
            dags list | grep gcs_to_bigquery_dag || echo "DAG not yet visible, may take a few minutes"

  test-data-pipeline:
    name: Test Data Pipeline
    runs-on: ubuntu-latest
    needs: deploy-dag
    if: github.ref == 'refs/heads/main' && github.event_name == 'push'

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v1
        with:
          credentials_json: ${{ secrets.GCP_SA_KEY }}

      - name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@v1

      - name: Create Test Data in GCS
        run: |
          PROJECT_ID="${{ secrets.GCP_PROJECT_ID }}"
          BUCKET="gs://${PROJECT_ID}-source"
          
          # Create sample CSV file
          cat > /tmp/test_data.csv << 'EOF'
          id,data,load_timestamp
          1,"{""name"":""Test Record 1""}",2025-11-19T00:00:00Z
          2,"{""name"":""Test Record 2""}",2025-11-19T00:00:00Z
          3,"{""name"":""Test Record 3""}",2025-11-19T00:00:00Z
          EOF
          
          # Upload to source bucket
          gsutil cp /tmp/test_data.csv ${BUCKET}/data/test_data.csv
          echo "Test data uploaded to ${BUCKET}/data/"

      - name: Trigger DAG Manually (Optional)
        run: |
          echo "To manually trigger the DAG, run:"
          echo "gcloud composer environments run gcs-to-bq-composer --location us-central1 dags trigger -- gcs_to_bigquery_dag"

  notify:
    name: Send Notifications
    runs-on: ubuntu-latest
    needs: [deploy-dag]
    if: always()

    steps:
      - name: Send Slack Notification
        if: always()
        uses: slackapi/slack-github-action@v1
        with:
          payload: |
            {
              "text": "GCP Composer DAG Deployment Status",
              "blocks": [
                {
                  "type": "section",
                  "text": {
                    "type": "mrkdwn",
                    "text": "*Deployment Status*: ${{ job.status == 'success' && 'âœ… Success' || 'âŒ Failed' }}\n*Ref*: ${{ github.ref }}\n*Commit*: ${{ github.sha }}"
                  }
                }
              ]
            }
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
          SLACK_WEBHOOK_TYPE: INCOMING_WEBHOOK
